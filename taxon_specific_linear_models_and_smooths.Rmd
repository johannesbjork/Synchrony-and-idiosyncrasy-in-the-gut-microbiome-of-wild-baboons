---
title: "Taxon-specific linear models and smooths"
author: Johannes Bj√∂rk
output: html_notebook
---

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
library(phyloseq)
library(compositions)
library(tidyverse)
library(patchwork)
library(ggExtra)
library(grid)
library(gridExtra)
library(ggpubr)
library(mgcv)
library(RColorBrewer)
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Prepare data for ASV-level linear models

# Read-in data
ps <- readRDS("ps.RDS")

metadata <- as(sample_data(ps), "data.frame")
ftbl <- as(otu_table(ps),"matrix") 
tax <- data.frame(as(tax_table(ps),"matrix")) 
colnames(ftbl) <- paste0("ASV_", 1:ncol(ftbl))
tax$feature_id <- paste0("ASV_", 1:ncol(ftbl))
rownames(tax) <- NULL

# Average samples collected from the same host in the group sampled the same date
index <- as.integer(factor(paste0(metadata$host, "_", metadata$grp, "_", metadata$collection_date)))
ftbl_avg <- data.frame(ftbl, index)
ftbl_avg <- as.matrix(aggregate(.~index, ftbl_avg, mean))
metadata_avg <- cbind(data.frame(metadata[,c("sample_id","collection_date","season","hydro_year","month", "grp", "host")]),
                       data.frame(index=index))
rownames(ftbl_avg) <- metadata_avg[!duplicated(index),]$sample_id
metadata_avg <- metadata_avg[metadata_avg$sample_id %in% rownames(ftbl_avg),]
ftbl_avg <- subset(ftbl_avg, select=-index)
ftbl_avg <- ftbl_avg[,colSums(ftbl_avg)>0]
ftbl_avg <- ceiling(ftbl_avg)

ftbl_avg_imp <- ftbl_avg 
ftbl_avg_imp[ftbl_avg_imp<0.0001] <- 0.65
ftbl_avg_clr <- compositions::clr(ftbl_avg_imp)

lm_data <- data.frame(ftbl_avg_clr) %>%
  rownames_to_column("sample_id") %>% 
  left_join(select(metadata, sample_id, season, grp, host), by="sample_id") %>% 
  mutate(season=relevel(factor(season, ordered=F), ref="Dry"),
         host=factor(host, ordered=F),
         grp=factor(grp, ordered=F))
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Fit ASV models

n_asvs <- ncol(lm_data[,-which(colnames(lm_data) %in% c('sample_id','season','grp','host'))])
asv_ids <- colnames(lm_data[,-which(colnames(lm_data) %in% c('sample_id','season','grp','host'))])

lm_asv_ls <- vector("list", n_asvs)
names(lm_asv_ls) <- asv_ids

for(asv in asv_ids) {
  tryCatch({
    # print(asv)
    m <- lmerTest::lmer(lm_data[,asv] ~ season + (1|host) + (1|grp), data=lm_data[,c(asv,"season","host","grp")])
    mm <- data.frame(coef(summary(m)))
    colnames(mm)[5] <- "p_val"
    lm_asv_ls[[asv]] <- mm
  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Prepare data for phylum-level linear models

# Read-in data
ps <- readRDS("ps.RDS")

ps <- ps %>% tax_glom("phylum")
metadata <- as(sample_data(ps), "data.frame")
ftbl <- as(otu_table(ps),"matrix") 
tax <- data.frame(as(tax_table(ps),"matrix")) 
colnames(ftbl) <- tax$phylum

# Average samples collected from the same host in the group sampled the same date
index <- as.integer(factor(paste0(metadata$host, "_", metadata$grp, "_", metadata$collection_date)))
ftbl_avg <- data.frame(ftbl, index)
ftbl_avg <- as.matrix(aggregate(.~index, ftbl_avg, mean))
metadata_avg <- cbind(data.frame(metadata[,c("sample_id","collection_date","season","hydro_year","month", "grp", "host")]),
                       data.frame(index=index))
rownames(ftbl_avg) <- metadata_avg[!duplicated(index),]$sample_id
metadata_avg <- metadata_avg[metadata_avg$sample_id %in% rownames(ftbl_avg),]
ftbl_avg <- subset(ftbl_avg, select=-index)
ftbl_avg <- ftbl_avg[,colSums(ftbl_avg)>0]
ftbl_avg <- ceiling(ftbl_avg)

# 0 imputation and clr-transformation
ftbl_avg_imp <- ftbl_avg
ftbl_avg_imp[ftbl_avg_imp<0.0001] <- 0.65
ftbl_avg_clr <- compositions::clr(ftbl_avg_imp)

lm_data <- data.frame(ftbl_avg_clr) %>%
  rownames_to_column("sample_id") %>% 
  left_join(select(metadata, sample_id, season, grp, host), by="sample_id") %>% 
  mutate(season=relevel(factor(season, ordered=F), ref="Dry"),
         host=factor(host, ordered=F),
         grp=factor(grp, ordered=F))
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Fit phylum models

n_phyla <- ncol(lm_data[,-which(colnames(lm_data) %in% c('sample_id','season','grp','host'))])
phylum_names <- colnames(lm_data[,-which(colnames(lm_data) %in% c('sample_id','season','grp','host'))])

lm_phy_ls <- vector("list", n_phyla)
names(lm_phy_ls) <- phylum_names

for(phy in phylum_names) {
  tryCatch({
    #print(phy)
    m <- lmerTest::lmer(lm_data[,phy] ~ season + (1|host) + (1|grp), data=lm_data[,c(phy,"season","host","grp")])
    mm <- data.frame(coef(summary(m)))
    colnames(mm)[5] <- "p_val"
    lm_phy_ls[[phy]] <- mm
  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Prepare data for family-level linear models

# Read-in data
ps <- readRDS("ps.RDS")

ps <- ps %>% tax_glom("family")
metadata <- as(sample_data(ps), "data.frame")
ftbl <- as(otu_table(ps),"matrix") 
tax <- data.frame(as(tax_table(ps),"matrix")) 
colnames(ftbl) <- tax$family

# Average samples (sequencing counts) collected from the same host in the group sampled the same date
index <- as.integer(factor(paste0(metadata$host, "_", metadata$grp, "_", metadata$collection_date)))
ftbl_avg <- data.frame(ftbl, index)
ftbl_avg <- as.matrix(aggregate(.~index, ftbl_avg, mean))
metadata_avg <- cbind(data.frame(metadata[,c("sample_id","collection_date","season","hydro_year","month", "grp", "host")]),
                       data.frame(index=index))
rownames(ftbl_avg) <- metadata_avg[!duplicated(index),]$sample_id
metadata_avg <- metadata_avg[metadata_avg$sample_id %in% rownames(ftbl_avg),]
ftbl_avg <- subset(ftbl_avg, select=-index)
ftbl_avg <- ftbl_avg[,colSums(ftbl_avg)>0]
ftbl_avg <- ceiling(ftbl_avg)

# 0 imputation and clr-transformation
ftbl_avg_imp <- ftbl_avg
ftbl_avg_imp[ftbl_avg_imp<0.0001] <- 0.65
ftbl_avg_clr <- compositions::clr(ftbl_avg_imp)

lm_data <- data.frame(ftbl_avg_clr) %>%
  rownames_to_column("sample_id") %>% 
  left_join(select(metadata, sample_id, season, grp, host), by="sample_id") %>% 
  mutate(season=relevel(factor(season, ordered=F), ref="Dry"),
         host=factor(host, ordered=F),
         grp=factor(grp, ordered=F))
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Fit family models

n_families <- ncol(lm_data[,-which(colnames(lm_data) %in% c('sample_id','season','grp','host'))])
family_names <- colnames(lm_data[,-which(colnames(lm_data) %in% c('sample_id','season','grp','host'))])

lm_fam_ls <- vector("list", n_families)
names(lm_fam_ls) <- family_names

for(fam in family_names) {
  tryCatch({
    #print(fam)
    m <- lmerTest::lmer(lm_data[,fam] ~ season + (1|host) + (1|grp), data=lm_data[,c(fam,"season","host","grp")])
    mm <- data.frame(coef(summary(m)))
    colnames(mm)[5] <- "p_val"
    lm_fam_ls[[fam]] <- mm
  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
## Prepare data for PCs and alpha diversity linear models

# Read-in data
ps <- readRDS("ps.RDS")

# Aitchison PCA = PCA on clr-transformed relative abundances
pseudocount <- 0.65 # for clr-transformation
clr_abund <- compositions::clr(as(otu_table(ps),"matrix")+pseudocount) # assumes samples are rows
pca_abund <- prcomp(clr_abund) # PCA

ftbl <- as(otu_table(ps),"matrix") 

# 3 alpha diversity metrics
alpha_divs <- vegan::renyi(ftbl, scales=c(0,1,2), hill=T) %>% 
  rename("richness"="0", "shannon"="1", "simpson"="2")

# Average PCs and alpha diversity indices collected from the same host in the group sampled the same date
metadata_avg <- as(sample_data(ps), "data.frame") %>% 
  left_join((data.frame(pca_abund$x[,1:3]) %>% rownames_to_column("sample_id")), by="sample_id") %>%
  left_join((data.frame(alpha_divs) %>% rownames_to_column("sample_id")), by="sample_id") %>% 
  group_by(host, grp, collection_date) %>%
  summarise(PC1=mean(PC1),
            PC2=mean(PC2),
            PC3=mean(PC3),
            richness=mean(richness),
            shannon=mean(shannon),
            simpson=mean(simpson)) %>%
  ungroup()

# metadata_avg lacks sample_id, we need to pick a sample_id for the samples that were averaged
metadata_avg <- metadata_avg %>% left_join((metadata %>%
                                              mutate(index=as.numeric(factor(paste0(host,"_",grp,"_",collection_date)))) %>%
                                              distinct(index, .keep_all=T) %>% select(sample_id, season, host, grp, collection_date)), by=c("host", "grp", "collection_date")) %>%
  mutate(row_names=sample_id) %>%
  column_to_rownames("row_names")

lm_data <- metadata_avg %>% 
  select(season, grp, host, PC1, PC2, PC3, richness, shannon, simpson) %>% 
  mutate(season=relevel(factor(season, ordered=F), ref="Dry"),
         host=factor(host, ordered=F),
         grp=factor(grp, ordered=F))
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Fit linear models for PCs and alpha diversity

lm_feat_ls <- vector("list", 6)
names(lm_feat_ls) <- colnames(lm_data[4:9])
for(feature in colnames(lm_data[4:9])) {
  tryCatch({
    #print(feature)
    m <- lmerTest::lmer(lm_data[,feature] ~ season + (1|host) + (1|grp), data=lm_data[,c(feature,"season","host","grp")])
    mm <- data.frame(coef(summary(m)))
    colnames(mm)[5] <- "p_val"
    lm_feat_ls[[feature]] <- mm
  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Combine all model resutls and correct for multiple hypothesis testing 

# N=341
lm_asv_df <- lm_asv_ls %>% 
  bind_rows(.id="feature_id") %>% 
  rownames_to_column("group") %>% 
  separate(group, into=c("group",NA)) %>% 
  filter(group!="") %>% 
  mutate(feature_type="ASVs")

# N=12
lm_phy_df <- lm_phy_ls %>% 
  bind_rows(.id="feature_id") %>% 
  rownames_to_column("group") %>% 
  separate(group, into=c("group",NA)) %>% 
  filter(group!="") %>% 
  mutate(feature_type="Phylum")

# N=34
lm_fam_df <- lm_fam_ls %>% 
  bind_rows(.id="feature_id") %>% 
  rownames_to_column("group") %>% 
  separate(group, into=c("group",NA)) %>% 
  filter(group!="") %>% 
  mutate(feature_type="Family")

# N=6
lm_feat_df <- lm_feat_ls %>% 
  bind_rows(.id="feature_id") %>% 
  rownames_to_column("group") %>% 
  separate(group, into=c("group",NA)) %>% 
  filter(group!="") %>% 
  mutate(feature_type="Community_phenotypes")

# In Fig. 2C we plot Community phenotypes, phyla and families. ASVs are plotted in Fig. S9

# Multiple hypothesis correction in the form of FDR correction (the Benjamini‚ÄìHochberg procedure) using the total number of models (n=6+12+34+341=393)
lm_df <- bind_rows(lm_phy_df, lm_fam_df, lm_feat_df) %>% 
  mutate(p_adj=p.adjust(p_val, method="BH", n=393),
         p_adj_sig=ifelse(p_adj < 0.05, "*", " "),
         sign=sign(Estimate),
         sign=ifelse(sign=="1","+","-"),
         sign=factor(sign, levels=c("+","-")),
         idx=row_number(),
         grouping=ifelse(feature_type!="Community_phenotypes", "Taxa", "Community_phenotypes")) %>% 
  group_by(feature_type) %>% 
  mutate(feature_id=fct_reorder(feature_id, Estimate, median)) %>%
  ungroup()
  
lm_df %>%  
  ggplot(aes(x=Estimate, y=feature_id, fill=sign)) +
  geom_bar(stat="identity") +
  scale_fill_manual(values=c("-"="#f6e8c3","+"="#7fbf7b")) +
  geom_text(aes(label=p_adj_sig), size=5, nudge_y=-0.25) +
  facet_wrap(vars(grouping), nrow=2, scales="free") +
  theme(
    legend.position="none",
    legend.title=element_blank(), 
    strip.background=element_blank(),
    strip.text=element_text(size=10, color="black"),
    plot.title=element_text(size=10, color="black"),
    panel.grid.major=element_blank(), 
    panel.grid.minor=element_blank(), 
    panel.background=element_rect(fill="white"),
    panel.border=element_rect(colour="black", fill=NA, size=1),
    axis.ticks.length=unit(0.10,"cm"), 
    axis.title=element_text(color="black", size=12),
    axis.text.x=element_text(color="black", size=12),
    axis.text.y=element_text(color="black", size=10),
    axis.title.x=element_text(color="black", size=12),
    strip.text.x=element_text(color="black", size=14)) +
  labs(y=NULL, x="Effect size")
```

```{r, Fig. S9, echo=T, eval=T, message=FALSE, warning=FALSE}
# Fig. S9
# Plot ASV level linear models

# Read-in data
ps <- readRDS("ps.RDS")

tax <- data.frame(as(tax_table(ps),"matrix")) 
colnames(ftbl) <- paste0("ASV_", 1:ncol(ftbl))
tax$feature_id <- paste0("ASV_", 1:ncol(ftbl))
rownames(tax) <- NULL
tax$rank <- paste(paste0("p_",tax$phylum), paste0("o_",tax$order), paste0("f_",tax$family), paste0("g_",tax$genus), sep=" ")
tax$rank <- gsub(x=tax$rank, pattern=" g_NA", replacement="")
tax$rank <- gsub(x=tax$rank, pattern="p_NA o_NA f_NA", replacement="unclassified")

# Find the 10 top and bottom significant features with the highest effect size 
(top_asv <- lm_asv_ls %>% 
  bind_rows(.id="feature_id") %>% 
  rownames_to_column("group") %>% 
  separate(group, into=c("group",NA)) %>% 
  filter(group!="") %>% 
  mutate(feature_type="ASVs") %>% 
  arrange(desc(Estimate)) %>% 
  mutate(p_adj=p.adjust(p_val, method="BH", n=393),
         p_adj_sig=ifelse(p_adj < 0.05, "*", " "),
         p_val=round(p_val,3),
         p_adj=round(p_adj,3),
         sign=sign(Estimate),
         sign=ifelse(sign=="1","+","-"),
         sign=factor(sign, levels=c("+","-")),
         feature_id=fct_reorder(feature_id, Estimate, median)) %>% 
  group_by(sign) %>% 
  filter(p_adj_sig=="*") %>% 
  slice_max(order_by=abs(Estimate), n=10) %>% 
  left_join(select(tax, feature_id, rank), by="feature_id"))

lm_asv_ls %>% 
  bind_rows(.id="feature_id") %>% 
  rownames_to_column("group") %>% 
  separate(group, into=c("group",NA)) %>% 
  filter(group!="") %>% 
  mutate(feature_type="ASVs") %>% 
  arrange(desc(Estimate)) %>% 
  mutate(p_adj=p.adjust(p_val, method="BH", n=393),
         p_adj_sig=ifelse(p_adj < 0.05, "*", " "),
         sign=sign(Estimate),
         sign=ifelse(sign=="1","+","-"),
         sign=factor(sign, levels=c("+","-")),
         feature_id=fct_reorder(feature_id, Estimate, median)) %>% 

  ggplot(aes(x=Estimate, y=feature_id, fill=sign)) +
  geom_bar(stat="identity") +
  scale_fill_manual(values=c("-"="#f6e8c3","+"="#7fbf7b")) +
  theme(
    legend.position="none",
    legend.title=element_blank(), 
    plot.title=element_text(size=14),
    panel.grid.major=element_blank(), 
    panel.grid.minor=element_blank(), 
    panel.background=element_rect(fill="white"),
    panel.border=element_rect(colour="black", fill=NA, size=1),
    axis.ticks.y=element_blank(),
    axis.ticks.length=unit(0.10,"cm"), 
    axis.text.x=element_text(size=12),
    axis.text.y=element_blank()) +
  labs(y=NULL, x="Effect size") 
```

# Below we reproduce Fig. S7 and S8. It takes a bit of time to estimate each taxon smooths with a 95% simultaneous confidence interval.
```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Prepare data for phylum-level smooths

# Read-in data
ps <- readRDS("ps.RDS") %>% 
  tax_glom("phylum")

metadata <- as(sample_data(ps), "data.frame")
ftbl <- as(otu_table(ps),"matrix") 
tax <- data.frame(as(tax_table(ps),"matrix")) 
colnames(ftbl) <- tax$phylum

# Average samples collected from the same host in the group sampled the same date
index <- as.integer(factor(paste0(metadata$host, "_", metadata$grp, "_", metadata$collection_date)))
ftbl_avg <- data.frame(ftbl, index)
ftbl_avg <- as.matrix(aggregate(.~index, ftbl_avg, mean))
metadata_avg <- cbind(data.frame(metadata[,c("sample_id","collection_date","season","hydro_year","month", "grp", "host")]),
                       data.frame(index=index))
rownames(ftbl_avg) <- metadata_avg[!duplicated(index),]$sample_id
metadata_avg <- metadata_avg[metadata_avg$sample_id %in% rownames(ftbl_avg),]
ftbl_avg <- subset(ftbl_avg, select=-index)
ftbl_avg <- ftbl_avg[,colSums(ftbl_avg)>0]
ftbl_avg <- ceiling(ftbl_avg)

# 0 imputation and clr-transformation
ftbl_avg_imp <- ftbl_avg
ftbl_avg_imp[ftbl_avg_imp<0.0001] <- 0.65
ftbl_avg_clr <- compositions::clr(ftbl_avg_imp)

# Redefine start and end of season based on rain_monthly: if >=1mm, we (re-)define it as wet season
# Below we fill-in missing collection and manually re-code season to wet if >=1mm rain in a particular month

# This is the rain data that we have gone thru manually
# for(hy in paste0(2000:2012, ":", 2001:2013)) {
# p <- as(sample_data(ps),"data.frame") %>% 
#     filter(hydro_year %in% str_split(hy,":",simplify=T)[,1]:str_split(hy,":",simplify=T)[,2]) %>% 
#     distinct(month, .keep_all=T) %>% 
#     select(collection_date, hydro_year, month, season, rain_monthly)
# print(p)
# }

metadata_avg_pad <- metadata_avg %>% 
  padr::pad(by="collection_date") %>% 
  mutate(time=as.integer(factor(collection_date)),
         month=factor(months(collection_date, abbreviate=T), levels=c("Nov","Dec","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct")),
         hydro_year=case_when(lubridate::month(collection_date) < 11 ~ lubridate::year(collection_date), lubridate::month(collection_date) >=11 ~ lubridate::year(collection_date)+1),
         season=case_when(lubridate::month(collection_date) %in% c(11,12,1,2,3,4,5) ~ "Wet",
                          lubridate::month(collection_date) %in% 6:10 ~ "Dry")) %>% 
  left_join((data.frame(ftbl_avg_clr) %>% rownames_to_column("sample_id")), by="sample_id") %>% 
  mutate(year_month=paste0(format(collection_date, "%Y"), "_", format(collection_date, "%b"))) %>% 
  mutate(season=if_else(year_month == "2000_Apr", replace(x=season, values="Dry"), season)) %>%
  mutate(season=if_else(year_month == "2000_May", replace(x=season, values="Dry"), season)) %>%
  mutate(season=if_else(year_month == "2002_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2004_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2005_Jun", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2005_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2006_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2007_Aug", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2007_Sep", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2007_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2008_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2009_Jun", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2010_Jun", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2010_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2011_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2012_Jun", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2012_Oct", replace(x=season, values="Wet"), season)) %>% 
  ungroup() %>% 
  mutate(hydro_year=if_else(year_month == "2002_Oct", replace(x=hydro_year, values=2003), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2004_Oct", replace(x=hydro_year, values=2005), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2005_Oct", replace(x=hydro_year, values=2006), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2006_Oct", replace(x=hydro_year, values=2007), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2007_Aug", replace(x=hydro_year, values=2008), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2007_Sep", replace(x=hydro_year, values=2008), hydro_year)) %>%
  mutate(hydro_year=if_else(year_month == "2007_Oct", replace(x=hydro_year, values=2008), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2008_Oct", replace(x=hydro_year, values=2009), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2010_Oct", replace(x=hydro_year, values=2011), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2011_Oct", replace(x=hydro_year, values=2012), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2012_Oct", replace(x=hydro_year, values=2013), hydro_year)) 

metadata_avg_pad_fitted <- metadata_avg_pad %>% 
  select(time, contains(gsub(x=colnames(ftbl_avg_clr), pattern=" ", replacement="."))) %>% 
  reshape2::melt(id.vars="time") %>% rename(taxon=variable, clr=value) 
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Fit phylum-level smooths

phylum_smooths <- vector("list", ncol(ftbl_avg_clr))
names(phylum_smooths) <- colnames(ftbl_avg_clr)

# Code to estimate smooths with 95% simultaneous confidence interval
rmvn <- function(n, mu, sig) { ## MVN random deviates
  L <- mroot(sig)
  m <- ncol(L)
  t(mu + L %*% matrix(rnorm(m*n), m, n))
}

for(phylum in colnames(ftbl_avg_clr)) {
  #print(phylum)
  m <- mgcv::gam(clr ~ s(time, k=30), data=metadata_avg_pad_fitted[metadata_avg_pad_fitted$taxon %in% phylum,][,c("time","clr")])
  
  # For 95% simultaneous confidence interval
  Vb <- vcov(m)
  newd <- metadata_avg_pad_fitted[metadata_avg_pad_fitted$taxon %in% phylum,][,c("time","clr")]
  pred <- predict(m, newd, se.fit=TRUE)
  se.fit <- pred$se.fit
  N <- 10000
  BUdiff <- rmvn(N, mu = rep(0, nrow(Vb)), sig = Vb)
  Cg <- predict(m, newd, type = "lpmatrix")
  simDev <- Cg %*% t(BUdiff)
  absDev <- abs(sweep(simDev, 1, se.fit, FUN = "/"))
  masd <- apply(absDev, 2L, max)
  crit <- quantile(masd, prob = 0.95, type = 8)
  pred <- transform(cbind(data.frame(pred), newd),
                    uprS = fit + (crit * se.fit),
                    lwrS = fit - (crit * se.fit))
  
  phylum_smooths[[phylum]] <- pred
}

phylum_smooths_df <- phylum_smooths %>% bind_rows(.id="taxon")
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Plot phylum-level smooths

# Season panels need to be adjusted for rainfall
rect_idx_season_pad <- cbind(  data.frame(hydro_year=rep(unique(metadata_avg_pad$hydro_year), each=2)),
                               data.frame(season=c("Wet","Dry"), stringsAsFactors=F),
                               data.frame(xmin=NA),
                               data.frame(xmax=NA),
                               data.frame(ymin=-Inf),
                               data.frame(ymax=Inf))

for(n in 1:nrow(rect_idx_season_pad)) {
  #print(n)
  rect_idx_season_pad$xmin[n] <- min(metadata_avg_pad[metadata_avg_pad$hydro_year %in% rect_idx_season_pad$hydro_year[n] & metadata_avg_pad$season %in% rect_idx_season_pad$season[n],]$time)
  rect_idx_season_pad$xmax[n] <- max(metadata_avg_pad[metadata_avg_pad$hydro_year %in% rect_idx_season_pad$hydro_year[n] & metadata_avg_pad$season %in% rect_idx_season_pad$season[n],]$time)
}
rect_idx_season_pad <- rect_idx_season_pad[-1,]
x_breaks_season_pad <- rect_idx_season_pad %>% group_by(hydro_year) %>% summarise(min=min(xmin),max=max(xmax))

# Plotting order based on phylum-specific linear models
phylum_order <- 
  lm_phy_df %>% 
    arrange(desc(Estimate), .by_group=T) %>% 
    mutate(feature_id=as_factor(feature_id))

# Spline colors
n <- length(phylum_order$feature_id)
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'div',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
cols <- sample(col_vector, n)
phylum_cols <- setNames(cols,phylum_order$feature_id)

phylum_smooths_df %>% 
  mutate(taxon=str_replace_all(taxon," ", ".")) %>% 
  left_join(select(phylum_order, feature_id, Estimate, feature_id), by=c("taxon"="feature_id")) %>% 
  mutate(taxon=factor(taxon, levels=phylum_order$feature_id)) %>%  

  ggplot(aes(x=time)) + 
  geom_rect(data=rect_idx_season_pad, inherit.aes=FALSE, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax, fill=factor(season)), alpha=0.7, show.legend=F) + 
  geom_ribbon(aes(ymin=lwrS, ymax=uprS, fill=factor(taxon))) +
  geom_line(aes(y=fit, x=time), size=1, color="black") +
  scale_fill_manual(values=c(setNames(c("#f6e8c3","#7fbf7b"), c("Dry","Wet")),phylum_cols)) +
  scale_color_manual(values=phylum_cols) +
  scale_x_continuous(breaks=x_breaks_season_pad$min, labels=x_breaks_season_pad$hydro_year, expand=c(0, 0)) +  
  theme(legend.position = "none",
        panel.grid.major=element_blank(), 
        panel.grid.minor=element_blank(),
        panel.background=element_blank(), 
        axis.ticks=element_line(color="black"),
        axis.ticks.length=unit(0.15,"cm"), 
        axis.text.x=element_text(size=12, angle=45, hjust=0.95, color="black"),
        axis.text.y=element_text(size=12,color="black"),
        axis.title=element_text(size=15,color="black"),
        strip.background=element_blank(),
        strip.text=element_text(size=12,color="black")) +
  guides(color=guide_legend(ncol=1)) +
  labs(x="Hydrological year", y="Log fold change") +
  facet_wrap(vars(taxon), nrow=5, scales="free_y") +
  geom_hline(yintercept=0, color="black",linetype="dashed")
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Prepare data for family-level smooths

# Read-in data
ps <- readRDS("ps.RDS") %>% 
  tax_glom("family")

metadata <- as(sample_data(ps), "data.frame")
ftbl <- as(otu_table(ps),"matrix") 
tax <- data.frame(as(tax_table(ps),"matrix")) 
colnames(ftbl) <- tax$family

# Average samples collected from the same host in the group sampled the same date
index <- as.integer(factor(paste0(metadata$host, "_", metadata$grp, "_", metadata$collection_date)))
ftbl_avg <- data.frame(ftbl, index)
ftbl_avg <- as.matrix(aggregate(.~index, ftbl_avg, mean))
metadata_avg <- cbind(data.frame(metadata[,c("sample_id","collection_date","season","hydro_year","month", "grp", "host")]),
                       data.frame(index=index))
rownames(ftbl_avg) <- metadata_avg[!duplicated(index),]$sample_id
metadata_avg <- metadata_avg[metadata_avg$sample_id %in% rownames(ftbl_avg),]
ftbl_avg <- subset(ftbl_avg, select=-index)
ftbl_avg <- ftbl_avg[,colSums(ftbl_avg)>0]
ftbl_avg <- ceiling(ftbl_avg)

# 0 imputation and clr-transformation
ftbl_avg_imp <- ftbl_avg
ftbl_avg_imp[ftbl_avg_imp<0.0001] <- 0.65
ftbl_avg_clr <- compositions::clr(ftbl_avg_imp)

# Redefine start and end of season based on rain_monthly: if >=1mm, we (re-)define it as wet season
# Below we fill-in missing collection and manually re-code season to wet if >=1mm rain in a particular month

# This is the rain data that we have gone thru manually
# for(hy in paste0(2000:2012, ":", 2001:2013)) {
# p <- as(sample_data(ps),"data.frame") %>% 
#     filter(hydro_year %in% str_split(hy,":",simplify=T)[,1]:str_split(hy,":",simplify=T)[,2]) %>% 
#     distinct(month, .keep_all=T) %>% 
#     select(collection_date, hydro_year, month, season, rain_monthly)
# print(p)
# }

metadata_avg_pad <- metadata_avg %>% 
  padr::pad(by="collection_date") %>% 
  mutate(time=as.integer(factor(collection_date)),
         month=factor(months(collection_date, abbreviate=T), levels=c("Nov","Dec","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct")),
         hydro_year=case_when(lubridate::month(collection_date) < 11 ~ lubridate::year(collection_date), lubridate::month(collection_date) >=11 ~ lubridate::year(collection_date)+1),
         season=case_when(lubridate::month(collection_date) %in% c(11,12,1,2,3,4,5) ~ "Wet",
                          lubridate::month(collection_date) %in% 6:10 ~ "Dry")) %>% 
  left_join((data.frame(ftbl_avg_clr) %>% rownames_to_column("sample_id")), by="sample_id") %>% 
  mutate(year_month=paste0(format(collection_date, "%Y"), "_", format(collection_date, "%b"))) %>% 
  mutate(season=if_else(year_month == "2000_Apr", replace(x=season, values="Dry"), season)) %>%
  mutate(season=if_else(year_month == "2000_May", replace(x=season, values="Dry"), season)) %>%
  mutate(season=if_else(year_month == "2002_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2004_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2005_Jun", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2005_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2006_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2007_Aug", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2007_Sep", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2007_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2008_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2009_Jun", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2010_Jun", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2010_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2011_Oct", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2012_Jun", replace(x=season, values="Wet"), season)) %>%
  mutate(season=if_else(year_month == "2012_Oct", replace(x=season, values="Wet"), season)) %>% 
  ungroup() %>% 
  mutate(hydro_year=if_else(year_month == "2002_Oct", replace(x=hydro_year, values=2003), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2004_Oct", replace(x=hydro_year, values=2005), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2005_Oct", replace(x=hydro_year, values=2006), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2006_Oct", replace(x=hydro_year, values=2007), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2007_Aug", replace(x=hydro_year, values=2008), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2007_Sep", replace(x=hydro_year, values=2008), hydro_year)) %>%
  mutate(hydro_year=if_else(year_month == "2007_Oct", replace(x=hydro_year, values=2008), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2008_Oct", replace(x=hydro_year, values=2009), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2010_Oct", replace(x=hydro_year, values=2011), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2011_Oct", replace(x=hydro_year, values=2012), hydro_year)) %>% 
  mutate(hydro_year=if_else(year_month == "2012_Oct", replace(x=hydro_year, values=2013), hydro_year)) 

metadata_avg_pad_fitted <- metadata_avg_pad %>% 
  select(time, contains(gsub(x=colnames(ftbl_avg_clr), pattern=" ", replacement="."))) %>% 
  reshape2::melt(id.vars="time") %>% rename(taxon=variable, clr=value) 
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Fit family-level smooths

family_smooths <- vector("list", ncol(ftbl_avg_clr))
names(family_smooths) <- colnames(ftbl_avg_clr)

# Code to estimate smooths with 95% simultaneous confidence interval
rmvn <- function(n, mu, sig) { ## MVN random deviates
  L <- mroot(sig)
  m <- ncol(L)
  t(mu + L %*% matrix(rnorm(m*n), m, n))
}

for(family in colnames(ftbl_avg_clr)) {
  #print(family)
  m <- mgcv::gam(clr ~ s(time, k=30), data=metadata_avg_pad_fitted[metadata_avg_pad_fitted$taxon %in% family,][,c("time","clr")])
  
  # For 95% simultaneous confidence interval
  Vb <- vcov(m)
  newd <- metadata_avg_pad_fitted[metadata_avg_pad_fitted$taxon %in% family,][,c("time","clr")]
  pred <- predict(m, newd, se.fit=TRUE)
  se.fit <- pred$se.fit
  N <- 10000
  BUdiff <- rmvn(N, mu = rep(0, nrow(Vb)), sig = Vb)
  Cg <- predict(m, newd, type = "lpmatrix")
  simDev <- Cg %*% t(BUdiff)
  absDev <- abs(sweep(simDev, 1, se.fit, FUN = "/"))
  masd <- apply(absDev, 2L, max)
  crit <- quantile(masd, prob = 0.95, type = 8)
  pred <- transform(cbind(data.frame(pred), newd),
                    uprS = fit + (crit * se.fit),
                    lwrS = fit - (crit * se.fit))
  
  family_smooths[[family]] <- pred
}

family_smooths_df <- family_smooths %>% bind_rows(.id="taxon")
```

```{r, echo=T, eval=T, message=FALSE, warning=FALSE}
# Plot family-level smooths

# Season panels need to be adjusted for rainfall
rect_idx_season_pad <- cbind(  data.frame(hydro_year=rep(unique(metadata_avg_pad$hydro_year), each=2)),
                               data.frame(season=c("Wet","Dry"), stringsAsFactors=F),
                               data.frame(xmin=NA),
                               data.frame(xmax=NA),
                               data.frame(ymin=-Inf),
                               data.frame(ymax=Inf))

for(n in 1:nrow(rect_idx_season_pad)) {
  #print(n)
  rect_idx_season_pad$xmin[n] <- min(metadata_avg_pad[metadata_avg_pad$hydro_year %in% rect_idx_season_pad$hydro_year[n] & metadata_avg_pad$season %in% rect_idx_season_pad$season[n],]$time)
  rect_idx_season_pad$xmax[n] <- max(metadata_avg_pad[metadata_avg_pad$hydro_year %in% rect_idx_season_pad$hydro_year[n] & metadata_avg_pad$season %in% rect_idx_season_pad$season[n],]$time)
}
rect_idx_season_pad <- rect_idx_season_pad[-1,]
x_breaks_season_pad <- rect_idx_season_pad %>% group_by(hydro_year) %>% summarise(min=min(xmin),max=max(xmax))

# Plotting order based on family-specific linear models
family_order <- 
  lm_fam_df %>% 
    arrange(desc(Estimate), .by_group=T) %>% 
    mutate(feature_id=as_factor(feature_id))

# Spline colors
n <- length(family_order$feature_id)
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'div',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
cols <- sample(col_vector, n)
family_cols <- setNames(cols,family_order$feature_id)

family_smooths_df %>% 
  mutate(taxon=str_replace_all(taxon," ", ".")) %>% 
  left_join(select(family_order, feature_id, Estimate, feature_id), by=c("taxon"="feature_id")) %>% 
  mutate(taxon=factor(taxon, levels=family_order$feature_id)) %>%  

  ggplot(aes(x=time)) + 
  geom_rect(data=rect_idx_season_pad, inherit.aes=FALSE, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax, fill=factor(season)), alpha=0.7, show.legend=F) + 
  geom_ribbon(aes(ymin=lwrS, ymax=uprS, fill=factor(taxon))) +
  geom_line(aes(y=fit, x=time), size=1, color="black") +
  scale_fill_manual(values=c(setNames(c("#f6e8c3","#7fbf7b"), c("Dry","Wet")),family_cols)) +
  scale_color_manual(values=family_cols) +
  scale_x_continuous(breaks=x_breaks_season_pad$min, labels=x_breaks_season_pad$hydro_year, expand=c(0, 0)) +  
  theme(legend.position = "none",
        panel.grid.major=element_blank(), 
        panel.grid.minor=element_blank(),
        panel.background=element_blank(), 
        axis.ticks=element_line(color="black"),
        axis.ticks.length=unit(0.15,"cm"), 
        axis.text.x=element_text(size=12, angle=45, hjust=0.95, color="black"),
        axis.text.y=element_text(size=12,color="black"),
        axis.title=element_text(size=15,color="black"),
        strip.background=element_blank(),
        strip.text=element_text(size=12,color="black")) +
  guides(color=guide_legend(ncol=1)) +
  labs(x="Hydrological year", y="Log fold change") +
  facet_wrap(vars(taxon), nrow=5, scales="free_y") +
  geom_hline(yintercept=0, color="black",linetype="dashed")
```